{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h5gseALZYQH"
      },
      "outputs": [],
      "source": [
        "# custom model and custom loop for mnist,fashion_mnist and cifer dataset\n",
        "\n",
        "# Model loading\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "df = pd.read_csv('/content/sample_data/mnist_train_small.csv')[:30000]\n",
        "\n",
        "def convert_and_shuflle(df,Target_class):\n",
        "    y = df[Target_class]\n",
        "    X = df.drop(Target_class,axis=1)\n",
        "    X = X/255.0\n",
        "    X_tens = tf.convert_to_tensor(X,dtype=tf.float32)\n",
        "    y_tens = tf.convert_to_tensor(y,dtype=tf.float32)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X_tens,y_tens))\n",
        "    dataset = dataset.shuffle(buffer_size = 2500, seed=40).batch(32)\n",
        "    len_ = tf.data.experimental.cardinality(dataset)\n",
        "    test_size = len_ // 5\n",
        "    test_set = (dataset.take(test_size))\n",
        "    valid_set = dataset.skip(test_size).take(test_size)\n",
        "    train_set = (dataset.skip(2*test_size))\n",
        "\n",
        "    train_set = train_set.prefetch(1)\n",
        "    test_set = test_set.cache()\n",
        "    valid_set = valid_set.cache()\n",
        "    return (train_set,test_set,valid_set)\n",
        "\n",
        "(train_set,test_set,valid_set) = convert_and_shuflle(df,'6')\n",
        "\n",
        "# custom model Making\n",
        "class Model(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(128,activation='relu',kernel_regularizer=None)\n",
        "    self.dense2 = tf.keras.layers.Dense(64,activation='relu',kernel_regularizer=None)\n",
        "    self.dense3 = tf.keras.layers.Dense(32,activation='relu',kernel_regularizer=None)\n",
        "    self.dense4 = tf.keras.layers.Dense(10,activation='softmax')\n",
        "    self.dropout = tf.keras.layers.Dropout(0.4)\n",
        "    self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
        "    self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "  def gaussian_noise(self,x):\n",
        "    return x + tf.random.normal(tf.shape(x),stddev=0.1)\n",
        "  def call(self,x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.gaussian_noise(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.batch_norm1(x)\n",
        "    x= self.dropout(x)\n",
        "    x = self.dense2(x)\n",
        "    x = self.batch_norm2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.dense3(x)\n",
        "    return self.dense4(x)\n",
        "\n",
        "    pass\n",
        "\n",
        "# // --- Custom Loop ---\\\\\n",
        "\n",
        "class Custom_Loop:\n",
        "  def __init__(self,model,optimizer_,loss_fn,train_set,valid_set,metrics_):\n",
        "    self.model = model\n",
        "    self.optimizer = optimizer_\n",
        "    self.loss_fn = loss_fn\n",
        "    self.train_set = train_set\n",
        "    self.valid_set = valid_set\n",
        "    self.train_loss_history = []\n",
        "    self.valid_loss_history = []\n",
        "    self.train_acc_history = []\n",
        "    self.valid_acc_history = []\n",
        "    self.train_loss_metric = tf.keras.metrics.Mean()\n",
        "    self.valid_loss_metric = tf.keras.metrics.Mean()\n",
        "    self.train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    self.valid_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  @tf.function\n",
        "  def training_step(self,x,y,x_valid,y_valid):\n",
        "\n",
        "      y_vaild_pred = self.model(x_valid)\n",
        "      loss_valid = self.loss_fn(y_valid,y_vaild_pred)\n",
        "      with tf.GradientTape() as tape:\n",
        "        y_pred = self.model(x)\n",
        "        loss = self.loss_fn(y,y_pred) + tf.reduce_sum(self.model.losses)\n",
        "      trainable_var = self.model.trainable_variables\n",
        "\n",
        "      grds = tape.gradient(loss,trainable_var)\n",
        "\n",
        "      optimizer.apply_gradients(zip(grds,trainable_var))\n",
        "\n",
        "      self.train_loss_metric.update_state(loss)\n",
        "      self.valid_loss_metric.update_state(loss_valid)\n",
        "      self.train_acc_metric.update_state(y,y_pred)\n",
        "      self.valid_acc_metric.update_state(y_valid,y_vaild_pred)\n",
        "\n",
        "\n",
        "  def loop(self, epochs, steps_per_epoch):\n",
        "        self.best_loss = float('inf')\n",
        "        self.paitance = 5\n",
        "        for epoch in range(epochs):\n",
        "            train_iter = iter(self.train_set.repeat())\n",
        "            valid_iter = iter(self.valid_set.repeat())\n",
        "\n",
        "            for step in range(steps_per_epoch):\n",
        "                x, y = next(train_iter)\n",
        "                x_valid, y_valid = next(valid_iter)\n",
        "                self.training_step(x, y, x_valid, y_valid)\n",
        "\n",
        "                vl_loss = self.valid_loss_metric.result()\n",
        "                if vl_loss < self.best_loss:\n",
        "                    self.best_loss = vl_loss\n",
        "                    self.paitance = 5\n",
        "                else:\n",
        "                    self.paitance -= 1\n",
        "            self.train_loss_history.append(self.train_loss_metric.result())\n",
        "            self.valid_loss_history.append(self.valid_loss_metric.result())\n",
        "            self.train_acc_history.append(self.train_acc_metric.result())\n",
        "            self.valid_acc_history.append(self.valid_acc_metric.result())\n",
        "\n",
        "            # Print epoch results\n",
        "            print(f\"Epoch {epoch+1} - \"\n",
        "                  f\"Train Loss: {self.train_loss_metric.result():.4f}, \"\n",
        "                  f\"Val Loss: {self.valid_loss_metric.result():.4f}, \"\n",
        "                  f\"Train Acc: {self.train_acc_metric.result():.4f}, \"\n",
        "                  f\"Val Acc: {self.valid_acc_metric.result():.4f}\")\n",
        "\n",
        "            # Reset metrics\n",
        "            self.train_loss_metric.reset_state()\n",
        "            self.valid_loss_metric.reset_state()\n",
        "            self.train_acc_metric.reset_state()\n",
        "            self.valid_acc_metric.reset_state()\n",
        "\n",
        "  def history(self):\n",
        "    train_loss = [float(x.numpy()) for x in self.train_loss_history]\n",
        "    valid_loss = [float(x.numpy()) for x in self.valid_loss_history]\n",
        "    train_acc = [float(x.numpy()) for x in self.train_acc_history]\n",
        "    valid_acc = [float(x.numpy()) for x in self.valid_acc_history]\n",
        "    return (train_loss,valid_loss,train_acc,valid_acc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.001,weight_decay=1e-4)\n",
        "metrics = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "model = Model()\n",
        "loop = Custom_Loop(model,optimizer,loss,train_set,valid_set,metrics)\n",
        "loop.loop(42,300)\n",
        "\n",
        "train_loss,valid_loss,train_acc,valid_acc = loop.history()\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(train_loss,label='train_loss')\n",
        "plt.plot(valid_loss,label='valid_loss')\n",
        "plt.legend()\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(train_acc,label='train_acc')\n",
        "plt.plot(valid_acc,label='valid_acc')\n",
        "plt.legend()\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(train_loss,label ='train_loss')\n",
        "plt.plot(train_acc,label ='train_acc')\n",
        "plt.legend()\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(valid_loss,label ='valid_loss')\n",
        "plt.plot(valid_acc,label ='valid_acc')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}